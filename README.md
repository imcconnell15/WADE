# WADE â€” Wide-Area Data Extraction

*A modular DFIR automation framework for staging, routing, and processing forensic artifacts at scaleâ€”built for austere ops, friendly to Splunk, and designed for real-world incident response.*

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ðŸŽ¯ Overview

WADE is a comprehensive forensic artifact processing pipeline that automatically:
- **Classifies** incoming evidence (E01, memory dumps, VM images, disk images, network configs)
- **Routes** artifacts through appropriate forensic tools (Volatility, Dissect, Hayabusa, Plaso, YARA, Bulk Extractor)
- **Enriches** data with metadata, host context, and case information
- **Outputs** normalized JSONL for Splunk ingestion and analysis

### Key Features

âœ… **Idempotent & Auditable** â€” Deterministic installs, per-file JSON event logs, SQLite-backed deduplication  
âœ… **Modular Architecture** â€” Independent classifiers, workers, and routing engine  
âœ… **Configuration-Driven** â€” YAML + environment variables for flexible tool selection  
âœ… **Online or Offline** â€” Works with pinned packages; air-gapped operation ready  
âœ… **Ops-Friendly** â€” systemd units, logrotate policies, comprehensive logging  
âœ… **Splunk-Native** â€” Direct integration with Splunk forwarders and indexes

---

## ðŸ—ï¸ Architecture

```mermaid
graph TB
    A[Staging Directories] --> B[StagingDaemon]
    B --> C[Classifier Registry]
    C --> D[Tool Router]
    D --> E[Ticket Builder]
    E --> F[Queue]
    F --> G[Queue Runner]
    G --> H[Worker Dispatch]
    H --> I1[Volatility Worker]
    H --> I2[Dissect Worker]
    H --> I3[Hayabusa Worker]
    H --> I4[Plaso Worker]
    H --> I5[YARA Worker]
    H --> I6[Bulk Extractor Worker]
    I1 --> J[JSONL Output]
    I2 --> J
    I3 --> J
    I4 --> J
    I5 --> J
    I6 --> J
    J --> K[Splunk]
